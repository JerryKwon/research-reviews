{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Collaborative Filtering vs Matrix Factorization Revisited\n",
    "\n",
    "\n",
    "https://arxiv.org/pdf/2005.09683.pdf\n",
    "\n",
    "추천시스템의 방법론 중에 Neural Net을 활용한 Neural Collaborative Filtering(NeuMF)가 전통적인 Matrix Factorization(MF)를 대체 방안이 될 수 있는지를 다양한 선례로 알아보는 Article\n",
    "\n",
    "## 1. Abstract\n",
    "전통적으로 dot product나 비슷한 수준을 상위로 정렬하는 방식은 추천시스템에 많이 채용되었다. 그러나 최근에는 이러한 유사성을 Neural Net으로 학습하는 Neural Collaborative Filitering 방식이 등장하고 있다. 해당 Article에서는 NeuMF를 위한 적절한 파라미터, dot product를 학습하기 위한 MLP의 추정함수 그리고 MLP 기반 알고리즘들이 너무 고비용적이고 왜 dot product 기반의 알고리즘을 사용해야 하는지 알아보자. 마지막으로 제목의 질문이 DNN을 기반으로 하는 NeuMF가 더 좋다라는 답변을 내포하지 않는 이유를 살펴본다.\n",
    "\n",
    "## 1.a. Prequisite; Neural Collaborative Filtering \n",
    "\n",
    "https://arxiv.org/pdf/1708.05031.pdf\n",
    "\n",
    "### reference\n",
    "\n",
    "* Collaborative Filtering using Deep Neural Networks (in Tensorflow)<br/>\n",
    "https://medium.com/@victorkohler/collaborative-filtering-using-deep-neural-networks-in-tensorflow-96e5d41a39a1\n",
    "* Neural Collaborative Filtering 논문 리뷰<br/>\n",
    "https://dnddnjs.github.io/recomm/2019/08/15/neural_collaborative_filtering/\n",
    "* Neural Collaborative Filtering with Movie Data<br/>\n",
    "https://calvinfeng.gitbook.io/machine-learning-notebook/supervised-learning/recommender/neural_collaborative_filtering\n",
    "* Neural Collaborative Filtering 리뷰<br/>\n",
    "https://itkmj.blogspot.com/2019/09/neural-collaborative-filtering.html\n",
    "* Neural Collaborative Filtering Implementation<br/>\n",
    "https://towardsdatascience.com/neural-collaborative-filtering-96cef1009401    \n",
    "\n",
    "### 1.a.1. Neural Collaborative Filtering Architecture\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src = \"https://miro.medium.com/max/1400/1*aP-Mx266ExwoWZPSdHtYpA.png\" />\n",
    "</div>\n",
    "\n",
    "1. Input Layer binarise a sparse vector for a user and item identification where:\n",
    "Item (i): 1 means the user u has interacted with Item(i)\n",
    "User (u): To identify the user\n",
    "2. Embedding layer is a fully connected layer that projects the sparse representation to a dense vector. The obtained user/item embeddings are the latent user/item vectors.\n",
    "3. Neural CF layers use Multi-layered neural architecture to map the latent vectors to prediction scores.\n",
    "4. The final output layer returns the predicted score by minimizing the pointwise loss/pairwise loss.\n",
    "\n",
    "### 1.a.2. Neural Matrix Factorization Architecture\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"imgs/NeuMF_vs_MF_NeuMF_archi.jpg\" />\n",
    "</div>\n",
    "\n",
    "### setup\n",
    "\n",
    "NeuMF를 검증하기 위한 데이터는 implicit feedback을 recommendation을 위한 데이터로 사용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definitions\n",
    "$X: Matrix; x: vectors; x: scalar$\n",
    "\n",
    "$[x,z]: x와 z벡터의 concatenation$\n",
    "\n",
    "$\\phi: R^d \\times R^d\\rightarrow R: 두개의 n차원 임베딩 벡터의 결합\\ p\\in R^d and\\ q \\in R^d$\n",
    "\n",
    "p는 user embedding, q는 item embedding\n",
    "\n",
    "$\\phi(p,q): user와\\ item의\\ 유사도$\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"imgs/NeuMF_vs_MF_simliarity.jpg\" />\n",
    "</div>\n",
    "\n",
    "### Dot Product (Matrix Factorization)\n",
    "\n",
    "$\\phi^dot(p,q):=<p,q>=p^Tq=\\overset{n}{\\underset{f=1}{\\sum}}p_fq_f$\n",
    "\n",
    "R: User-Item Matrix\n",
    "P: User-Latent Factor Matrix\n",
    "Q: Item-Latent Factor Matrix\n",
    "\n",
    "희소행렬로 구성된 User-Item Matrix(R)을 임의의 잠재 요인의 개수 L을 선정하여 User-Latent Factor Matrix(P)와 Item-Latent Factor Matrix(Q)로 분리한다. 그리고 두 분리한 P와 Q Matrix를 다시 내적한 결과를 R과 오차값을 통해 조정함으로써 다른 희소행렬의 값을 0이 아닌 값으로 채운다.\n",
    "\n",
    "$R:\\ m\\times{n}\\ matrix;\\ P:\\ m\\times{l}\\ matrix;\\ Q:\\ n\\times{l}\\ matrix;\\$\n",
    "\n",
    "1. P와 Q행렬은 1이하의 임의의 실수값으로 random하게 부여한다.\n",
    "2. P와 Q행렬의 내적을 계산한다.\n",
    "3. 2의 결과 값을 R행렬의 0이 아닌값과 오차를 계산한다.\n",
    "4. 오차를 활용하여 P와 Q행렬의 값을 update 한다.\n",
    "5. 임의의 시행 동안 2~4의 과정을 반복\n",
    "\n",
    "R 행렬의 임의의 non-zero element i행 j열의 R[i,j]값에 대하여 Update 실시\n",
    "\n",
    "$P[i]=P[i]+learning\\_rate*{e_{ij}*Q[j]-r\\_lambda*P[i]}$\n",
    "\n",
    "$Q[j]=Q[j]+learning\\_rate*{e_{ij}*P[i]-r\\_lambda*Q[j]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")),\"data\")\n",
    "movies = pd.read_csv(os.path.join(path,\"movies.csv\"))\n",
    "ratings = pd.read_csv(os.path.join(path,\"ratings.csv\"))\n",
    "ratings = ratings[[\"userId\",\"movieId\",\"rating\"]]\n",
    "ratings_matrix = ratings.pivot_table(\"rating\",index=\"userId\",columns=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_movies = pd.merge(ratings,movies,on=\"movieId\")\n",
    "ratings_matrix = rating_movies.pivot_table(\"rating\",index=\"userId\",columns=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(R,P, Q, non_zeros):\n",
    "  actual = []\n",
    "  preds = []\n",
    "\n",
    "  for i,j,r in non_zeros:\n",
    "    actual.append(r)\n",
    "    preds.append(np.dot(P[i,:], Q[j,:].T))\n",
    "\n",
    "  result = mean_squared_error(actual,preds)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(R,K,steps=200,learning_rate=0.01,r_lambda = 0.01):\n",
    "  num_users, num_items = R.shape\n",
    "\n",
    "  np.random.seed(1)\n",
    "  P = np.random.normal(scale=1./K, size=(num_users,K))\n",
    "  Q = np.random.normal(scale=1./K, size=(num_items,K))\n",
    "\n",
    "  prev_rmse = 10000\n",
    "  break_count = 0\n",
    "\n",
    "  non_zeros = [ (i,j,R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n",
    "\n",
    "  for step in range(steps):\n",
    "    for i,j,r in non_zeros:\n",
    "      eij = r - np.dot(P[i,:],Q[j,:].T)\n",
    "\n",
    "      P[i,:] = P[i,:] + learning_rate*(eij * Q[j,:] - r_lambda*P[i,:])\n",
    "      Q[j,:] = Q[j,:] + learning_rate*(eij * P[i,:] - r_lambda*Q[j,:])\n",
    "\n",
    "    rmse = get_rmse(R,P, Q, non_zeros)\n",
    "    if(step % 10) == 0:\n",
    "      print(\"### iteration step: \",step,\" rmse: \",rmse)\n",
    "\n",
    "  return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### iteration step:  0  rmse:  8.423705034701914\n",
      "### iteration step:  10  rmse:  0.5381350082096514\n",
      "### iteration step:  20  rmse:  0.2616873953526066\n",
      "### iteration step:  30  rmse:  0.13884289422659946\n",
      "### iteration step:  40  rmse:  0.08766445000765151\n",
      "### iteration step:  50  rmse:  0.06352180214146708\n",
      "### iteration step:  60  rmse:  0.05056878035552725\n",
      "### iteration step:  70  rmse:  0.04278880610647561\n",
      "### iteration step:  80  rmse:  0.03768808288452511\n",
      "### iteration step:  90  rmse:  0.03411439291872163\n",
      "### iteration step:  100  rmse:  0.031481147723579454\n",
      "### iteration step:  110  rmse:  0.02946450167499212\n",
      "### iteration step:  120  rmse:  0.027872910023915155\n",
      "### iteration step:  130  rmse:  0.026586255346641597\n",
      "### iteration step:  140  rmse:  0.02552546850158907\n",
      "### iteration step:  150  rmse:  0.024636400788713323\n",
      "### iteration step:  160  rmse:  0.023880751551717972\n",
      "### iteration step:  170  rmse:  0.02323069360565542\n",
      "### iteration step:  180  rmse:  0.02266554560767273\n",
      "### iteration step:  190  rmse:  0.02216963440759845\n"
     ]
    }
   ],
   "source": [
    "P, Q = matrix_factorization(ratings_matrix.values,K=50,steps=200,learning_rate=0.01,r_lambda=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>'71 (2014)</th>\n",
       "      <th>'Hellboy': The Seeds of Creation (2004)</th>\n",
       "      <th>'Round Midnight (1986)</th>\n",
       "      <th>'Salem's Lot (2004)</th>\n",
       "      <th>'Til There Was You (1997)</th>\n",
       "      <th>'Tis the Season for Love (2015)</th>\n",
       "      <th>'burbs, The (1989)</th>\n",
       "      <th>'night Mother (1986)</th>\n",
       "      <th>(500) Days of Summer (2009)</th>\n",
       "      <th>*batteries not included (1987)</th>\n",
       "      <th>...</th>\n",
       "      <th>Zulu (2013)</th>\n",
       "      <th>[REC] (2007)</th>\n",
       "      <th>[REC]² (2009)</th>\n",
       "      <th>[REC]³ 3 Génesis (2012)</th>\n",
       "      <th>anohana: The Flower We Saw That Day - The Movie (2013)</th>\n",
       "      <th>eXistenZ (1999)</th>\n",
       "      <th>xXx (2002)</th>\n",
       "      <th>xXx: State of the Union (2005)</th>\n",
       "      <th>¡Three Amigos! (1986)</th>\n",
       "      <th>À nous la liberté (Freedom for Us) (1931)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.055084</td>\n",
       "      <td>4.092018</td>\n",
       "      <td>3.564130</td>\n",
       "      <td>4.502167</td>\n",
       "      <td>3.981215</td>\n",
       "      <td>1.271694</td>\n",
       "      <td>3.603274</td>\n",
       "      <td>2.333266</td>\n",
       "      <td>5.091749</td>\n",
       "      <td>3.972454</td>\n",
       "      <td>...</td>\n",
       "      <td>1.402608</td>\n",
       "      <td>4.208382</td>\n",
       "      <td>3.705957</td>\n",
       "      <td>2.720514</td>\n",
       "      <td>2.787331</td>\n",
       "      <td>3.475076</td>\n",
       "      <td>3.253458</td>\n",
       "      <td>2.161087</td>\n",
       "      <td>4.010495</td>\n",
       "      <td>0.859474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.170119</td>\n",
       "      <td>3.657992</td>\n",
       "      <td>3.308707</td>\n",
       "      <td>4.166521</td>\n",
       "      <td>4.311890</td>\n",
       "      <td>1.275469</td>\n",
       "      <td>4.237972</td>\n",
       "      <td>1.900366</td>\n",
       "      <td>3.392859</td>\n",
       "      <td>3.647421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973811</td>\n",
       "      <td>3.528264</td>\n",
       "      <td>3.361532</td>\n",
       "      <td>2.672535</td>\n",
       "      <td>2.404456</td>\n",
       "      <td>4.232789</td>\n",
       "      <td>2.911602</td>\n",
       "      <td>1.634576</td>\n",
       "      <td>4.135735</td>\n",
       "      <td>0.725684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.307073</td>\n",
       "      <td>1.658853</td>\n",
       "      <td>1.443538</td>\n",
       "      <td>2.208859</td>\n",
       "      <td>2.229486</td>\n",
       "      <td>0.780760</td>\n",
       "      <td>1.997043</td>\n",
       "      <td>0.924908</td>\n",
       "      <td>2.970700</td>\n",
       "      <td>2.551446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520354</td>\n",
       "      <td>1.709494</td>\n",
       "      <td>2.281596</td>\n",
       "      <td>1.782833</td>\n",
       "      <td>1.635173</td>\n",
       "      <td>1.323276</td>\n",
       "      <td>2.887580</td>\n",
       "      <td>1.042618</td>\n",
       "      <td>2.293890</td>\n",
       "      <td>0.396941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.628629</td>\n",
       "      <td>3.035550</td>\n",
       "      <td>2.575746</td>\n",
       "      <td>3.706912</td>\n",
       "      <td>3.430636</td>\n",
       "      <td>0.706441</td>\n",
       "      <td>3.330280</td>\n",
       "      <td>1.978826</td>\n",
       "      <td>4.560368</td>\n",
       "      <td>2.775710</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046116</td>\n",
       "      <td>2.912178</td>\n",
       "      <td>2.479592</td>\n",
       "      <td>2.231915</td>\n",
       "      <td>1.888629</td>\n",
       "      <td>2.211364</td>\n",
       "      <td>0.645603</td>\n",
       "      <td>1.585734</td>\n",
       "      <td>3.542892</td>\n",
       "      <td>0.591540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.116148</td>\n",
       "      <td>3.084761</td>\n",
       "      <td>2.747679</td>\n",
       "      <td>3.783490</td>\n",
       "      <td>3.946990</td>\n",
       "      <td>0.883259</td>\n",
       "      <td>1.958953</td>\n",
       "      <td>1.757317</td>\n",
       "      <td>2.054312</td>\n",
       "      <td>2.775258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956159</td>\n",
       "      <td>3.893975</td>\n",
       "      <td>2.717024</td>\n",
       "      <td>2.002443</td>\n",
       "      <td>2.053337</td>\n",
       "      <td>3.983639</td>\n",
       "      <td>2.099626</td>\n",
       "      <td>1.423718</td>\n",
       "      <td>2.490428</td>\n",
       "      <td>0.531403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9719 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "title   '71 (2014)  'Hellboy': The Seeds of Creation (2004)  \\\n",
       "userId                                                        \n",
       "1         3.055084                                 4.092018   \n",
       "2         3.170119                                 3.657992   \n",
       "3         2.307073                                 1.658853   \n",
       "4         2.628629                                 3.035550   \n",
       "5         2.116148                                 3.084761   \n",
       "\n",
       "title   'Round Midnight (1986)  'Salem's Lot (2004)  \\\n",
       "userId                                                \n",
       "1                     3.564130             4.502167   \n",
       "2                     3.308707             4.166521   \n",
       "3                     1.443538             2.208859   \n",
       "4                     2.575746             3.706912   \n",
       "5                     2.747679             3.783490   \n",
       "\n",
       "title   'Til There Was You (1997)  'Tis the Season for Love (2015)  \\\n",
       "userId                                                               \n",
       "1                        3.981215                         1.271694   \n",
       "2                        4.311890                         1.275469   \n",
       "3                        2.229486                         0.780760   \n",
       "4                        3.430636                         0.706441   \n",
       "5                        3.946990                         0.883259   \n",
       "\n",
       "title   'burbs, The (1989)  'night Mother (1986)  (500) Days of Summer (2009)  \\\n",
       "userId                                                                          \n",
       "1                 3.603274              2.333266                     5.091749   \n",
       "2                 4.237972              1.900366                     3.392859   \n",
       "3                 1.997043              0.924908                     2.970700   \n",
       "4                 3.330280              1.978826                     4.560368   \n",
       "5                 1.958953              1.757317                     2.054312   \n",
       "\n",
       "title   *batteries not included (1987)  \\\n",
       "userId                                   \n",
       "1                             3.972454   \n",
       "2                             3.647421   \n",
       "3                             2.551446   \n",
       "4                             2.775710   \n",
       "5                             2.775258   \n",
       "\n",
       "title                     ...                      Zulu (2013)  [REC] (2007)  \\\n",
       "userId                    ...                                                  \n",
       "1                         ...                         1.402608      4.208382   \n",
       "2                         ...                         0.973811      3.528264   \n",
       "3                         ...                         0.520354      1.709494   \n",
       "4                         ...                         1.046116      2.912178   \n",
       "5                         ...                         0.956159      3.893975   \n",
       "\n",
       "title   [REC]² (2009)  [REC]³ 3 Génesis (2012)  \\\n",
       "userId                                           \n",
       "1            3.705957                 2.720514   \n",
       "2            3.361532                 2.672535   \n",
       "3            2.281596                 1.782833   \n",
       "4            2.479592                 2.231915   \n",
       "5            2.717024                 2.002443   \n",
       "\n",
       "title   anohana: The Flower We Saw That Day - The Movie (2013)  \\\n",
       "userId                                                           \n",
       "1                                                2.787331        \n",
       "2                                                2.404456        \n",
       "3                                                1.635173        \n",
       "4                                                1.888629        \n",
       "5                                                2.053337        \n",
       "\n",
       "title   eXistenZ (1999)  xXx (2002)  xXx: State of the Union (2005)  \\\n",
       "userId                                                                \n",
       "1              3.475076    3.253458                        2.161087   \n",
       "2              4.232789    2.911602                        1.634576   \n",
       "3              1.323276    2.887580                        1.042618   \n",
       "4              2.211364    0.645603                        1.585734   \n",
       "5              3.983639    2.099626                        1.423718   \n",
       "\n",
       "title   ¡Three Amigos! (1986)  À nous la liberté (Freedom for Us) (1931)  \n",
       "userId                                                                    \n",
       "1                    4.010495                                   0.859474  \n",
       "2                    4.135735                                   0.725684  \n",
       "3                    2.293890                                   0.396941  \n",
       "4                    3.542892                                   0.591540  \n",
       "5                    2.490428                                   0.531403  \n",
       "\n",
       "[5 rows x 9719 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_matrix = P.dot(Q.T)\n",
    "ratings_pred_matrix = pd.DataFrame(data=pred_matrix, index=ratings_matrix.index, columns = ratings_matrix.columns)\n",
    "ratings_pred_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learned Similarity\n",
    "\n",
    "* $f_{w,b}(x) = \\sigma(Wx+b), \\sigma(z)=[\\sigma(z_1),...,\\sigma(z_{out})]$<br/>\n",
    "$f:R^{d_{in}}\\rightarrow R^{d_{out}};\\ W\\in R^{in\\times out};\\ b\\in R^{out}; \\sigma: R\\rightarrow R$\n",
    "* MLP: $\\phi^{MLP}(p,q):=f_{W_l,b_l}(...f_{W_1,b_1}([p,q])...)$\n",
    "* NeuMF: $\\phi^{NeuMF}(p,q):=\\phi^{MLP}(p_{[1,...,j],q_{[i...j]}}) + \\phi^{GMF}(p_{[1,...,j],q_{[i...j]}})$\n",
    "* GMF: $\\phi^{GMF}(p,q):=\\sigma(w_T(p\\odot{q}))=\\sigma(<w\\odot{p,q}>)=\\sigma(\\overset{d}{\\underset{f=1}{\\sum}}w_fp_fq_f)$\n",
    "\n",
    "## 3. Revisiting NCF Experiments\n",
    "\n",
    "Prequsite NeuMF 논문에서 살펴본 것과 같이, 추천을 위한 데이터는 implicit feedback만을 사용하였다. 그리고 추천의 검증을 위해 사용하는 Metric은 Hit ratio(해당 item이 정답 item list에 들어있는 비율)와 NDCG(Rank 추정을 위한 Metric)가 있다.\n",
    "\n",
    "### NDCG\n",
    "\n",
    "nDCG를 계산할 때, 정답 안에서의 순서는 무시됩니다. 예를 들어서 곡에 대한 ground truth 가 [1, 2, 3, 4, 5] 이었을 때, 예상 곡 리스트로 [10, 20, 1, 2, 3] 을 제출하든 [10, 20, 2, 3, 1] 를 제출하든, 뒤에 3개가 정답이었기 때문에 두 제출의 점수는 동일합니다. 다만, [1, 2, 3, 10, 20] 을 제출할 경우, nDCG의 정의에 의해 [10, 20, 1, 2, 3] 보다 점수가 높습니다. 채점 코드는 다음과 같으니 참고해 주세요.\n",
    "\n",
    "    def _ndcg(self, gt, rec):\n",
    "        dcg = 0.0\n",
    "        for i, r in enumerate(rec):\n",
    "            if r in gt:\n",
    "                dcg += 1.0 / np.log(i + 2)\n",
    "        return dcg / self._idcgs[len(gt)]\n",
    "\n",
    "### Results\n",
    "\n",
    "<div align=\"center\">\n",
    "<p><b>Perfomances of Methods</b></p>\n",
    "<img src=\"imgs/NeuMF_vs_MF_performance.jpg\" />\n",
    "</div>\n",
    "\n",
    "#### Matrix Factorization vs MLP\n",
    "해당 논문에서 보려고 하는 취지와 달리, dot product를 통한 MF가 MLP보다 훨씬 높은 성능을 보인다. 따라서, MLP를 이용한 방식이 MF를 이용한 방식보다 뛰어나다고 말할 수 없다. 그리고 MLP를 이용한 방식은 정확도 뿐만 아니라 model parameter 학습 및 비용적인 측면을 고려했을 때 단점이 보인다.\n",
    "\n",
    "#### Matrix Factorization vs NeuMF\n",
    "NeuMF는 dot product와 MLP모델을 동시에 합하여 처리하는 모델이다. 전반적으로 MLP보다는 약간의 성능상승이 있지만 MF보다는 전반적으로 훨씬 좋지 못하다.\n",
    "\n",
    "그리고 GMF와 MLP를 모두 Fine Tuning후에 합치는 구조는 위의 Tuning을 거치지 않고 합치는 모델보다는 성능이 높다. 그러나 전반적은 MF의 성능보다는 낮다.\n",
    "\n",
    "그러나 GMF와 MLP를 합치는 것은 도움이 된다는 것을 알 수 있다.\n",
    "\n",
    "### Futher comparison\n",
    "\n",
    "<img src=\"imgs/NeuMF_vs_MF_futher_comparison.jpg\" />\n",
    "\n",
    "## 4. Learning a Dot Product with MLP is Hard\n",
    "\n",
    "MLP는 dot product를 활용한 방식보다 더 강력한 embedding vector들의 combiner이다. 그러나 이는 MLP에 사용되는 target function의 학습이 얼마나 어려운지를 모르고 하는 말이다.\n",
    "\n",
    "MLP에서 class function이 클수록 더 많은 파라미터를 요구한다. 더 나아가 학습에 있어서 더 많은 데이터를 요구하여 이러한 target function을 학습하는데 어려움이 있을 것이다.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"imgs/NeuMF_vs_MF_MLP_perf.jpg\"/>\n",
    "</div>\n",
    "\n",
    "NeuMF 논문에서 두 user, item의 embedding 벡터를 concat한 2d size의 벡터와 [4h, 2h, h]로 이어지는 3개의 은닉층을 활용하여 신경망 모델을 생성했다. 이 논문에서 은닉층의 뉴런 값을 $h=d/2$로 추천한다. 그리고 embedding vector공간 d에 따라 학습해야 하는 파라미터의 수는 $18d^2$이다(e.g) d=8: 1,152, d=64: 73,728, d=256: 1,179,648).\n",
    "\n",
    "위의 도식으로, 넓은 수준의 은닉층 공간과 많은 양의 훈련 데이터만 있다면 MLP는 학습이 가능하다는 것을 알 수 있다. \n",
    "\n",
    "## 5. Applicability of Dot Product Models\n",
    "\n",
    "recommendation system은 추천의 결과 만큼 이를 계산하고 도출하는 시간적인 문제 또한 중요하다. 그래서 우리가 시도했던 알고리즘들의 시간복잡도를 살펴보자.\n",
    "\n",
    "* dot product: $O(d)$ <br/>\n",
    ": sublinear time algorithm 有\n",
    "* MLP-learned similarity: $O(d^2)$ <br/>\n",
    ": sublinear time algorithm 無\n",
    "\n",
    "만약, 점수를 계산해야하는 n개의 아이템이 있다면, $O(dn)\\ vs\\ O(d^2n)$의 시간복잡도를 가진다.\n",
    "\n",
    "거대한 어플리케이션의 경우에 n은 수백만, d는 수백의 값을 가진다. 그럼에도 dot product 방식은 낮은 복잡도로 인해 요구되는 시간내로 유의한 결과를 낼 수 있는 것이다. 그러나 dot product 방식에도 효율적으로 유사한 아이템들을 찾아내야 하는 문제가 있다. 여기에는 'approximate nearest neighbor search'와 'maximum inner product search' 두 가지 방식이 있다.\n",
    "\n",
    "따라서 실시간 top-N recommendation에 있어서 적합한 방법이 아니다.\n",
    "\n",
    "## 6. Related Work\n",
    "\n",
    "### 6.1. Dot products at the Output Layer of DNNs\n",
    "(<a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\">**'Deep Neural Networks for YouTube Recommendations'**</a> of Candidate Generate Model)\n",
    "\n",
    "이 방법 또한 Neural Net을 사용하지만 MLP는 아니다. 이는 일반적인 다중 분류 문제로 취급하여 해결한다. input x를 DNN f를 거친 하나의 embedding한 vector로 변환한다.\n",
    "\n",
    "$input\\  x;\\ label\\ y \\in {1,...,n}; DNN:\\ f(x)\\in{R^d}$\n",
    "\n",
    "위의 결과로 얻은 vector $R^d$는 vector의 점수를 나타내기 위해 class label을 활용한다. 일반적으로 ㅑinput 결과인 $R^d$를 class matrix $Q\\in{R^{n\\times{d}}}$와 곱하여 n class들에 대한 스칼라 점수를 계산한다. 이 결과에 대해 softmax cross entrophy를 활용하여 손실을 계산한다.\n",
    "\n",
    "$Qf(x) = Qp = [<p,q_i>]_{i=1}^{n}$\n",
    "\n",
    "결국 이는 input embedding과 label embedding을 dot product하여 결과를 얻는것을 말한다.\n",
    "\n",
    "\n",
    "### 6.2. MLPs at the Output Layer of DNNs\n",
    "\n",
    "### 6.3. Specialized Structures inside a DNN\n",
    "\n",
    "## 7. Conclusion\n",
    "\n",
    "결과적으로는 dot product 방식을 통해 embedding을 combine하는 것이 MLP나 NeuMF 보다 더 나은 선택이라는 것을 알아보았다. dot product방식을 사용하도록 권고하는것은 여러 긍정적인 효과를 가지게 될 것이다.\n",
    "\n",
    "1. Model의 실제 업무와 관련성 제고\n",
    "2. Modeling 및 학습에 있어서 단순화를 통해 실행 및 이해를 증진"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
